{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ay_dupdHlBIu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8uuAKFlzlBIz"
   },
   "outputs": [],
   "source": [
    "# using original train dataset\n",
    "train_df = pd.read_csv(\"wordEmbeddingTrain.csv\")\n",
    "test_df = pd.read_csv(\"wordEmbeddingTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "u69jwQMylBI3",
    "outputId": "922e6165-6a54-4826-fba4-75f076becbe2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train dataset: (29635, 101)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.140486</td>\n",
       "      <td>-0.708271</td>\n",
       "      <td>-0.382102</td>\n",
       "      <td>-0.410084</td>\n",
       "      <td>-0.203693</td>\n",
       "      <td>0.105790</td>\n",
       "      <td>0.197683</td>\n",
       "      <td>0.158858</td>\n",
       "      <td>-0.004087</td>\n",
       "      <td>0.501946</td>\n",
       "      <td>0.817093</td>\n",
       "      <td>-0.007407</td>\n",
       "      <td>0.084096</td>\n",
       "      <td>0.549983</td>\n",
       "      <td>-0.148468</td>\n",
       "      <td>0.345249</td>\n",
       "      <td>-0.718528</td>\n",
       "      <td>0.661399</td>\n",
       "      <td>0.060167</td>\n",
       "      <td>-0.015378</td>\n",
       "      <td>0.159862</td>\n",
       "      <td>-0.303505</td>\n",
       "      <td>-0.947532</td>\n",
       "      <td>0.441177</td>\n",
       "      <td>-0.485557</td>\n",
       "      <td>0.551304</td>\n",
       "      <td>-0.400632</td>\n",
       "      <td>0.915736</td>\n",
       "      <td>-0.117861</td>\n",
       "      <td>-0.275671</td>\n",
       "      <td>-0.158642</td>\n",
       "      <td>-0.162210</td>\n",
       "      <td>0.081044</td>\n",
       "      <td>-0.118758</td>\n",
       "      <td>0.126228</td>\n",
       "      <td>-0.255362</td>\n",
       "      <td>0.073483</td>\n",
       "      <td>-0.360309</td>\n",
       "      <td>-0.461073</td>\n",
       "      <td>-0.682586</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.860870</td>\n",
       "      <td>-0.041735</td>\n",
       "      <td>-0.112784</td>\n",
       "      <td>0.335660</td>\n",
       "      <td>0.236203</td>\n",
       "      <td>-0.203994</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>-0.841251</td>\n",
       "      <td>-0.376188</td>\n",
       "      <td>-0.200862</td>\n",
       "      <td>-0.440811</td>\n",
       "      <td>0.066923</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>-0.671191</td>\n",
       "      <td>0.330062</td>\n",
       "      <td>0.128769</td>\n",
       "      <td>-0.233154</td>\n",
       "      <td>-0.423077</td>\n",
       "      <td>0.074356</td>\n",
       "      <td>-0.118002</td>\n",
       "      <td>0.464461</td>\n",
       "      <td>0.396795</td>\n",
       "      <td>0.337315</td>\n",
       "      <td>0.210631</td>\n",
       "      <td>0.182505</td>\n",
       "      <td>-0.030054</td>\n",
       "      <td>0.241693</td>\n",
       "      <td>-0.189385</td>\n",
       "      <td>-0.671315</td>\n",
       "      <td>-0.322100</td>\n",
       "      <td>-1.064298</td>\n",
       "      <td>-0.205313</td>\n",
       "      <td>-0.604041</td>\n",
       "      <td>0.209205</td>\n",
       "      <td>-0.325033</td>\n",
       "      <td>0.153971</td>\n",
       "      <td>0.497229</td>\n",
       "      <td>0.458049</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.411015</td>\n",
       "      <td>-0.790592</td>\n",
       "      <td>-0.897963</td>\n",
       "      <td>-0.338375</td>\n",
       "      <td>-0.284312</td>\n",
       "      <td>0.302484</td>\n",
       "      <td>-0.070416</td>\n",
       "      <td>-0.069028</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.582238</td>\n",
       "      <td>0.641988</td>\n",
       "      <td>-0.065851</td>\n",
       "      <td>0.442992</td>\n",
       "      <td>0.808749</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0.340279</td>\n",
       "      <td>-0.537265</td>\n",
       "      <td>0.854679</td>\n",
       "      <td>0.249314</td>\n",
       "      <td>0.412822</td>\n",
       "      <td>0.034011</td>\n",
       "      <td>-0.191674</td>\n",
       "      <td>-0.653370</td>\n",
       "      <td>0.034254</td>\n",
       "      <td>-1.052022</td>\n",
       "      <td>0.188792</td>\n",
       "      <td>-0.416396</td>\n",
       "      <td>0.331440</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>-0.395125</td>\n",
       "      <td>0.062894</td>\n",
       "      <td>-0.161823</td>\n",
       "      <td>0.451315</td>\n",
       "      <td>0.225832</td>\n",
       "      <td>0.772677</td>\n",
       "      <td>-0.261482</td>\n",
       "      <td>0.052034</td>\n",
       "      <td>-0.054870</td>\n",
       "      <td>0.392352</td>\n",
       "      <td>-0.734915</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.428407</td>\n",
       "      <td>-0.573357</td>\n",
       "      <td>-0.145710</td>\n",
       "      <td>-0.138064</td>\n",
       "      <td>-0.185041</td>\n",
       "      <td>-0.636128</td>\n",
       "      <td>-0.482763</td>\n",
       "      <td>-0.399819</td>\n",
       "      <td>-0.655939</td>\n",
       "      <td>0.231350</td>\n",
       "      <td>-0.202902</td>\n",
       "      <td>-0.908067</td>\n",
       "      <td>0.096744</td>\n",
       "      <td>-0.163150</td>\n",
       "      <td>-0.652637</td>\n",
       "      <td>0.407531</td>\n",
       "      <td>0.320159</td>\n",
       "      <td>-0.429656</td>\n",
       "      <td>0.013194</td>\n",
       "      <td>0.174726</td>\n",
       "      <td>-0.118575</td>\n",
       "      <td>0.264148</td>\n",
       "      <td>0.514540</td>\n",
       "      <td>0.538285</td>\n",
       "      <td>0.257320</td>\n",
       "      <td>0.662347</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0.469471</td>\n",
       "      <td>-0.347117</td>\n",
       "      <td>-0.409639</td>\n",
       "      <td>-0.146003</td>\n",
       "      <td>-0.772914</td>\n",
       "      <td>0.038109</td>\n",
       "      <td>-0.847527</td>\n",
       "      <td>0.188956</td>\n",
       "      <td>-1.158004</td>\n",
       "      <td>0.093777</td>\n",
       "      <td>0.500449</td>\n",
       "      <td>0.182480</td>\n",
       "      <td>math.DS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.274633</td>\n",
       "      <td>-1.035805</td>\n",
       "      <td>-0.625783</td>\n",
       "      <td>-0.478151</td>\n",
       "      <td>0.262160</td>\n",
       "      <td>0.351610</td>\n",
       "      <td>0.210195</td>\n",
       "      <td>0.236449</td>\n",
       "      <td>0.049997</td>\n",
       "      <td>0.170583</td>\n",
       "      <td>1.042437</td>\n",
       "      <td>-0.289420</td>\n",
       "      <td>0.194248</td>\n",
       "      <td>0.588932</td>\n",
       "      <td>-0.151895</td>\n",
       "      <td>-0.086544</td>\n",
       "      <td>-0.522886</td>\n",
       "      <td>0.157788</td>\n",
       "      <td>0.240884</td>\n",
       "      <td>0.267894</td>\n",
       "      <td>0.181665</td>\n",
       "      <td>-0.429905</td>\n",
       "      <td>-0.771415</td>\n",
       "      <td>0.283736</td>\n",
       "      <td>-0.423372</td>\n",
       "      <td>0.067313</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>0.566220</td>\n",
       "      <td>-0.530708</td>\n",
       "      <td>-0.740464</td>\n",
       "      <td>-0.056403</td>\n",
       "      <td>-0.132329</td>\n",
       "      <td>0.130324</td>\n",
       "      <td>0.445718</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>-0.221498</td>\n",
       "      <td>0.243620</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>-0.505254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.893118</td>\n",
       "      <td>0.033947</td>\n",
       "      <td>-0.052350</td>\n",
       "      <td>-0.135523</td>\n",
       "      <td>-0.139931</td>\n",
       "      <td>-0.546910</td>\n",
       "      <td>-0.193552</td>\n",
       "      <td>-0.497427</td>\n",
       "      <td>-0.946763</td>\n",
       "      <td>0.470572</td>\n",
       "      <td>-0.249931</td>\n",
       "      <td>-0.693920</td>\n",
       "      <td>0.035093</td>\n",
       "      <td>0.216054</td>\n",
       "      <td>-0.706345</td>\n",
       "      <td>0.090972</td>\n",
       "      <td>-0.029947</td>\n",
       "      <td>-0.402164</td>\n",
       "      <td>-0.146975</td>\n",
       "      <td>0.244872</td>\n",
       "      <td>-0.690961</td>\n",
       "      <td>0.211039</td>\n",
       "      <td>0.555475</td>\n",
       "      <td>0.356738</td>\n",
       "      <td>0.373525</td>\n",
       "      <td>0.270387</td>\n",
       "      <td>-0.086202</td>\n",
       "      <td>-0.017531</td>\n",
       "      <td>-0.583491</td>\n",
       "      <td>-0.699735</td>\n",
       "      <td>0.507972</td>\n",
       "      <td>-1.007552</td>\n",
       "      <td>-0.483059</td>\n",
       "      <td>-0.487506</td>\n",
       "      <td>0.429888</td>\n",
       "      <td>-0.885947</td>\n",
       "      <td>-0.069881</td>\n",
       "      <td>0.263815</td>\n",
       "      <td>0.319821</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.005348</td>\n",
       "      <td>-0.107721</td>\n",
       "      <td>0.211413</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>-0.310092</td>\n",
       "      <td>0.690397</td>\n",
       "      <td>-0.191305</td>\n",
       "      <td>-0.050948</td>\n",
       "      <td>0.295349</td>\n",
       "      <td>0.350828</td>\n",
       "      <td>0.395079</td>\n",
       "      <td>0.061064</td>\n",
       "      <td>-0.411787</td>\n",
       "      <td>0.452803</td>\n",
       "      <td>-0.955696</td>\n",
       "      <td>0.286555</td>\n",
       "      <td>-0.240239</td>\n",
       "      <td>0.399184</td>\n",
       "      <td>-0.038166</td>\n",
       "      <td>0.262422</td>\n",
       "      <td>0.492287</td>\n",
       "      <td>-0.401936</td>\n",
       "      <td>-0.647855</td>\n",
       "      <td>0.406254</td>\n",
       "      <td>-0.230929</td>\n",
       "      <td>0.313915</td>\n",
       "      <td>0.030999</td>\n",
       "      <td>1.323934</td>\n",
       "      <td>-0.128252</td>\n",
       "      <td>-0.244788</td>\n",
       "      <td>-0.688295</td>\n",
       "      <td>-0.267328</td>\n",
       "      <td>-0.075071</td>\n",
       "      <td>-0.000950</td>\n",
       "      <td>-0.048877</td>\n",
       "      <td>-0.012726</td>\n",
       "      <td>0.144117</td>\n",
       "      <td>-0.699378</td>\n",
       "      <td>-0.029636</td>\n",
       "      <td>-0.360249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557799</td>\n",
       "      <td>0.265272</td>\n",
       "      <td>-0.048223</td>\n",
       "      <td>0.258731</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>-0.400214</td>\n",
       "      <td>-0.335888</td>\n",
       "      <td>-0.206921</td>\n",
       "      <td>-1.141477</td>\n",
       "      <td>-0.062828</td>\n",
       "      <td>-0.076323</td>\n",
       "      <td>0.030817</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>-0.105759</td>\n",
       "      <td>-0.373355</td>\n",
       "      <td>0.236038</td>\n",
       "      <td>0.065127</td>\n",
       "      <td>-0.257887</td>\n",
       "      <td>-0.348451</td>\n",
       "      <td>0.309993</td>\n",
       "      <td>-0.116354</td>\n",
       "      <td>0.696131</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.028553</td>\n",
       "      <td>-0.465432</td>\n",
       "      <td>-0.258324</td>\n",
       "      <td>0.214632</td>\n",
       "      <td>0.663038</td>\n",
       "      <td>0.235052</td>\n",
       "      <td>-0.191465</td>\n",
       "      <td>0.594372</td>\n",
       "      <td>-0.179300</td>\n",
       "      <td>-0.217202</td>\n",
       "      <td>-0.343062</td>\n",
       "      <td>0.777707</td>\n",
       "      <td>0.067506</td>\n",
       "      <td>0.594999</td>\n",
       "      <td>0.238857</td>\n",
       "      <td>0.295559</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.331930</td>\n",
       "      <td>-0.507421</td>\n",
       "      <td>-0.363805</td>\n",
       "      <td>-0.526135</td>\n",
       "      <td>0.168097</td>\n",
       "      <td>0.475303</td>\n",
       "      <td>-0.427657</td>\n",
       "      <td>0.082572</td>\n",
       "      <td>0.265829</td>\n",
       "      <td>0.375759</td>\n",
       "      <td>0.498758</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.580635</td>\n",
       "      <td>0.196778</td>\n",
       "      <td>-0.581300</td>\n",
       "      <td>0.036001</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.238772</td>\n",
       "      <td>-0.306868</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.608958</td>\n",
       "      <td>-0.389964</td>\n",
       "      <td>-0.936416</td>\n",
       "      <td>0.046494</td>\n",
       "      <td>-0.199522</td>\n",
       "      <td>0.185793</td>\n",
       "      <td>-0.312735</td>\n",
       "      <td>0.672138</td>\n",
       "      <td>-0.401558</td>\n",
       "      <td>-0.331315</td>\n",
       "      <td>-0.112465</td>\n",
       "      <td>0.169780</td>\n",
       "      <td>0.374365</td>\n",
       "      <td>-0.331305</td>\n",
       "      <td>0.158887</td>\n",
       "      <td>0.100658</td>\n",
       "      <td>0.117208</td>\n",
       "      <td>-0.289045</td>\n",
       "      <td>0.078530</td>\n",
       "      <td>-0.659751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.650633</td>\n",
       "      <td>0.315824</td>\n",
       "      <td>-0.028734</td>\n",
       "      <td>0.103695</td>\n",
       "      <td>-0.309480</td>\n",
       "      <td>0.011387</td>\n",
       "      <td>-0.184515</td>\n",
       "      <td>-0.682596</td>\n",
       "      <td>-0.679377</td>\n",
       "      <td>-0.076989</td>\n",
       "      <td>-0.178071</td>\n",
       "      <td>-0.287388</td>\n",
       "      <td>-0.134399</td>\n",
       "      <td>-0.137119</td>\n",
       "      <td>-0.750574</td>\n",
       "      <td>0.271493</td>\n",
       "      <td>0.291778</td>\n",
       "      <td>-0.094905</td>\n",
       "      <td>-0.685056</td>\n",
       "      <td>0.669625</td>\n",
       "      <td>0.114055</td>\n",
       "      <td>0.166026</td>\n",
       "      <td>0.016774</td>\n",
       "      <td>0.140728</td>\n",
       "      <td>0.328139</td>\n",
       "      <td>0.044087</td>\n",
       "      <td>0.446870</td>\n",
       "      <td>0.643369</td>\n",
       "      <td>0.124932</td>\n",
       "      <td>-0.122167</td>\n",
       "      <td>0.391183</td>\n",
       "      <td>-0.473992</td>\n",
       "      <td>-0.101979</td>\n",
       "      <td>-0.329689</td>\n",
       "      <td>-0.091322</td>\n",
       "      <td>-0.407838</td>\n",
       "      <td>-0.014392</td>\n",
       "      <td>0.398557</td>\n",
       "      <td>0.600941</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2  ...        98        99   labels\n",
       "0 -0.140486 -0.708271 -0.382102  ...  0.497229  0.458049       cs\n",
       "1  0.411015 -0.790592 -0.897963  ...  0.500449  0.182480  math.DS\n",
       "2 -0.274633 -1.035805 -0.625783  ...  0.263815  0.319821       cs\n",
       "3 -0.005348 -0.107721  0.211413  ...  0.238857  0.295559       cs\n",
       "4  0.331930 -0.507421 -0.363805  ...  0.398557  0.600941       cs\n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_df['index']\n",
    "print('Shape of the train dataset: ' + str(train_df.shape))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "g5h6UtoVlBI-",
    "outputId": "a961f00c-cba4-42fb-d2b1-dadbb73c6e39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 \n",
      "\n",
      "0         0\n",
      "1         1\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "29630     0\n",
      "29631    14\n",
      "29632     0\n",
      "29633     0\n",
      "29634    14\n",
      "Name: labels, Length: 29635, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Creating the dependent variable class\n",
    "factor = pd.factorize(train_df['labels'])\n",
    "train_df.labels = factor[0]\n",
    "definitions = factor[1]\n",
    "\n",
    "print(len(definitions), '\\n')\n",
    "print(train_df.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "woKv8S6slBJE"
   },
   "outputs": [],
   "source": [
    "#Splitting the data into independent and dependent variables\n",
    "\n",
    "X = train_df.iloc[:,0:100].values\n",
    "y = train_df.iloc[:,100].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GbdYi-y6lBJK"
   },
   "outputs": [],
   "source": [
    "# Creating the Training and Test set from data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RYSjjqsElBJR"
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s8VB19J_lBJW",
    "outputId": "afdbe73f-0888-4086-9571-53b81fffb0a8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "[CV] C=0.03 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=0.03, score=0.532, total= 2.0min\n",
      "[CV] C=0.03 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=0.03, score=0.529, total= 2.0min\n",
      "[CV] C=0.03 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=0.03, score=0.531, total= 2.0min\n",
      "[CV] C=0.04 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=0.04, score=0.532, total= 2.3min\n",
      "[CV] C=0.04 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=0.04, score=0.532, total= 2.2min\n",
      "[CV] C=0.04 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=0.04, score=0.531, total= 2.2min\n",
      "[CV] C=0.05 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 12.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=0.05, score=0.531, total= 2.5min\n",
      "[CV] C=0.05 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 15.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=0.05, score=0.530, total= 2.4min\n",
      "[CV] C=0.05 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 17.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=0.05, score=0.530, total= 2.3min\n",
      "[CV] C=0.06 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 19.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=0.06, score=0.531, total= 2.7min\n",
      "[CV] C=0.06 ..........................................................\n",
      "[CV] .............................. C=0.06, score=0.531, total= 2.6min\n",
      "[CV] C=0.06 ..........................................................\n",
      "[CV] .............................. C=0.06, score=0.530, total= 2.5min\n",
      "[CV] C=0.07 ..........................................................\n",
      "[CV] .............................. C=0.07, score=0.530, total= 2.8min\n",
      "[CV] C=0.07 ..........................................................\n",
      "[CV] .............................. C=0.07, score=0.531, total= 2.7min\n",
      "[CV] C=0.07 ..........................................................\n",
      "[CV] .............................. C=0.07, score=0.530, total= 2.6min\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................... C=0.1, score=0.526, total= 3.3min\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................... C=0.1, score=0.528, total= 3.0min\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................... C=0.1, score=0.530, total= 3.0min\n",
      "[CV] C=0.5 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=0.5, score=0.516, total= 4.9min\n",
      "[CV] C=0.5 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=0.5, score=0.517, total= 4.9min\n",
      "[CV] C=0.5 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed: 59.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=0.5, score=0.516, total= 4.9min\n",
      "{'C': 0.04}\n",
      "LogisticRegression(C=0.04, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# multinomial\n",
    "# Determine optimised C \n",
    "# https://stackoverflow.com/questions/60868629/valueerror-solver-lbfgs-supports-only-l2-or-none-penalties-got-l1-penalty\n",
    "# https://stackoverflow.com/questions/32074630/training-logistic-regression-using-scikit-learn-for-multi-class-classification\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-defintions\n",
    "\n",
    "parameters = {'C':[0.03, 0.04, 0.05, 0.06, 0.07, 0.1, 0.5]}\n",
    "grid_lr = GridSearchCV(LogisticRegression(multi_class='multinomial', penalty= 'l2', solver = 'saga', max_iter=500), parameters, cv=3, refit = True, verbose = 10)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(grid_lr.best_params_)\n",
    "print(grid_lr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zEOSFujqlBJb"
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_predictition = grid_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "RS9GyzmYlBJe",
    "outputId": "5b8487a3-fe36-4d47-ba65-ea04d70d20c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1764    2   11 ...    0    0    0]\n",
      " [  17   36    0 ...    0    0    0]\n",
      " [ 132    0    2 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   3    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]] \n",
      "\n",
      "Accuracy: 0.5348405601484731\n",
      "Precision: 0.26712530255594935\n",
      "Recall: 0.20716071943705647\n",
      "F1 score: 0.21534968733774457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Performance metrics\n",
    "recall = recall_score(y_test, y_predictition, average='macro')\n",
    "precision = precision_score(y_test, y_predictition, average='macro')\n",
    "f1score = f1_score(y_test, y_predictition, average='macro')\n",
    "accuracy = accuracy_score(y_test, y_predictition)\n",
    "\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test, y_predictition),'\\n')\n",
    "print('Accuracy:', str(accuracy))\n",
    "print('Precision:', str(precision))\n",
    "print('Recall:', str(recall))\n",
    "print('F1 score:', str(f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "f6MfOy-jlBJh"
   },
   "outputs": [],
   "source": [
    "# test\n",
    "test_data = test_df.iloc[:,0:100].values\n",
    "test_data_scaled = scaler.fit_transform(test_data)\n",
    "test_predictition = grid_lr.predict(test_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Pe_03sLKlBJj"
   },
   "outputs": [],
   "source": [
    "test_df=test_df.rename(columns = {'index':'test_id'})\n",
    "test_df['label'] = definitions[test_predictition] # convert to original labels\n",
    "test_df.drop(train_df.iloc[:,0:100], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "nO2UBJJHlBJm",
    "outputId": "321a5349-2078-4145-e2cc-c1be6a155c32",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>stat.AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>math.RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>physics.optics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id           label\n",
       "0        1         stat.AP\n",
       "1        2              cs\n",
       "2        3              cs\n",
       "3        4         math.RT\n",
       "4        5  physics.optics"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "aCWNVd2WlBJo"
   },
   "outputs": [],
   "source": [
    "test_df.to_csv('./Predictions_lr_multinomial_saga_word2vec.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Logistic Regression with word-embedding (non-suplemented data)-multinomial-saga",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
