{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate\n",
    "import sklearn.svm as svm\n",
    "from sklearn.svm import LinearSVC\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf vectorizer generation part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I did not use the target directory so need to add it after unifying the path of the files in text pre-processing.ipynb file.\n",
    "\n",
    "# training data\n",
    "clean_train = []\n",
    "\n",
    "for line in open(\"train.txt\", \"r\"):\n",
    "    clean_train.append(line.strip().split(','))\n",
    "\n",
    "for n in range(0,len(clean_train)):\n",
    "    clean_train[n] = clean_train[n][1:]\n",
    "    \n",
    "# testing data\n",
    "clean_test = []\n",
    "\n",
    "for line in open(\"test.txt\", \"r\"):\n",
    "    clean_test.append(line.strip().split(','))\n",
    "\n",
    "for n in range(0,len(clean_test)):\n",
    "    clean_test[n] = clean_test[n][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "train_df = pd.DataFrame(clean_train)\n",
    "train_df['Words'] = train_df[train_df.columns[1:]].apply(\n",
    "    lambda x: ','.join(x.dropna().astype(str)),\n",
    "    axis=1)\n",
    "train_df.drop(train_df.iloc[:,1:281], inplace=True, axis=1)\n",
    "train_df=train_df.rename(columns = {0:'Label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs</td>\n",
       "      <td>save,special,case,current,training,method,gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>math.DS</td>\n",
       "      <td>consider,dynamical,system,finitely,many,equili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cs</td>\n",
       "      <td>consider,discrete,dynamical,system,ant,like,ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cs</td>\n",
       "      <td>retrofit,technique,inject,external,resource,wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs</td>\n",
       "      <td>approach,decision,make,uncertainty,belief,func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29633</th>\n",
       "      <td>cs</td>\n",
       "      <td>powerful,deep,network,architecture,generative,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29634</th>\n",
       "      <td>math.AG</td>\n",
       "      <td>develop,mixed,characteristic,version,mori,muka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29635</th>\n",
       "      <td>cs</td>\n",
       "      <td>complex,analysis,wind,number,measure,number,ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29636</th>\n",
       "      <td>cs</td>\n",
       "      <td>discus,secure,computation,modular,sum,multiple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29637</th>\n",
       "      <td>math.AG</td>\n",
       "      <td>paper,define,notion,graph,trace,kernel,general...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29638 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label                                              Words\n",
       "0           cs  save,special,case,current,training,method,gene...\n",
       "1      math.DS  consider,dynamical,system,finitely,many,equili...\n",
       "2           cs  consider,discrete,dynamical,system,ant,like,ag...\n",
       "3           cs  retrofit,technique,inject,external,resource,wo...\n",
       "4           cs  approach,decision,make,uncertainty,belief,func...\n",
       "...        ...                                                ...\n",
       "29633       cs  powerful,deep,network,architecture,generative,...\n",
       "29634  math.AG  develop,mixed,characteristic,version,mori,muka...\n",
       "29635       cs  complex,analysis,wind,number,measure,number,ti...\n",
       "29636       cs  discus,secure,computation,modular,sum,multiple...\n",
       "29637  math.AG  paper,define,notion,graph,trace,kernel,general...\n",
       "\n",
       "[29638 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = train_df.Words.values.tolist()\n",
    "train_label = train_df.Label.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data\n",
    "test_df = pd.DataFrame(clean_test)\n",
    "test_df['Words'] = test_df[test_df.columns[0:]].apply(\n",
    "    lambda x: ','.join(x.dropna().astype(str)),\n",
    "    axis=1)\n",
    "test_df.drop(test_df.iloc[:,0:280], inplace=True, axis=1)\n",
    "test_df[\"Label\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>method,model,average,become,important,tool,dea...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unmanned,aerial,vehicle,uav,system,increasingl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paper,propose,new,loss,function,call,generaliz...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>show,integrate,weak,morphism,lie,algebra,cross...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>caustic,occur,widely,dynamic,take,shape,classi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7405</th>\n",
       "      <td>statistical,inference,evolutionary,parameter,m...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7406</th>\n",
       "      <td>present,deep,learn,framework,base,generative,a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7407</th>\n",
       "      <td>cell,receptor,tcr,repertoire,data,contain,info...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7408</th>\n",
       "      <td>paper,provide,modern,synthesis,classic,inverse...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7409</th>\n",
       "      <td>experiment,currently,harvest,lhc,collision,dat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7410 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Words  Label\n",
       "0     method,model,average,become,important,tool,dea...    NaN\n",
       "1     unmanned,aerial,vehicle,uav,system,increasingl...    NaN\n",
       "2     paper,propose,new,loss,function,call,generaliz...    NaN\n",
       "3     show,integrate,weak,morphism,lie,algebra,cross...    NaN\n",
       "4     caustic,occur,widely,dynamic,take,shape,classi...    NaN\n",
       "...                                                 ...    ...\n",
       "7405  statistical,inference,evolutionary,parameter,m...    NaN\n",
       "7406  present,deep,learn,framework,base,generative,a...    NaN\n",
       "7407  cell,receptor,tcr,repertoire,data,contain,info...    NaN\n",
       "7408  paper,provide,modern,synthesis,classic,inverse...    NaN\n",
       "7409  experiment,currently,harvest,lhc,collision,dat...    NaN\n",
       "\n",
       "[7410 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = test_df.Words.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training & Valid sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "test_size = 0.2\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_words, train_label, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TF-IDF with n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/45883679/train-model-fails-because-list-object-has-no-attribute-lower\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "tfidfv = TfidfVectorizer(tokenizer=dummy,preprocessor=dummy,ngram_range=(1,3))\n",
    "\n",
    "# training\n",
    "train_tfidf = tfidfv.fit_transform(x_train)\n",
    "train_target = np.asarray(y_train)\n",
    "\n",
    "#valid\n",
    "valid_tfidf = tfidfv.transform(x_valid)\n",
    "valid_target = np.asarray(y_valid)\n",
    "\n",
    "# testing\n",
    "test_tfidf = tfidfv.transform(test_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/18165213/how-much-time-does-take-train-svm-classifier\n",
    "# to save computation time, we will use a linear svc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear SVC model\n",
    "linear_model = LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train a model with a tuned Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.8 ...........................................................\n",
      "[CV] ............................... C=0.8, score=0.524, total=  55.3s\n",
      "[CV] C=0.8 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   55.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=0.8, score=0.523, total= 1.4min\n",
      "[CV] C=0.8 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=0.8, score=0.529, total=  56.6s\n",
      "[CV] C=0.825 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  3.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................. C=0.825, score=0.524, total= 1.2min\n",
      "[CV] C=0.825 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................. C=0.825, score=0.523, total= 1.4min\n",
      "[CV] C=0.825 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  5.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................. C=0.825, score=0.530, total=  56.1s\n",
      "[CV] C=0.85 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  6.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=0.85, score=0.523, total= 1.4min\n",
      "[CV] C=0.85 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  8.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=0.85, score=0.522, total= 1.1min\n",
      "[CV] C=0.85 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  9.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=0.85, score=0.530, total= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 11.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.825}\n",
      "LinearSVC(C=0.825, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/24121018/sklearn-gridsearch-how-to-print-out-progress-during-the-execution\n",
    "# C and loss\n",
    "parameters_svm = {'C':[0.8, 0.825, 0.85]}\n",
    "grid_svm = GridSearchCV(LinearSVC(), parameters_svm, scoring= 'accuracy', cv=3, refit = True, verbose = 10)\n",
    "\n",
    "#train a model\n",
    "grid_svm.fit(train_tfidf, train_target)\n",
    "\n",
    "print(grid_svm.best_params_)\n",
    "print(grid_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prediction on a valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_predictition = grid_svm.predict(valid_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- performance metrics of the  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[22  0  6 ...  0  0  0]\n",
      " [ 0  4  0 ...  0  0  0]\n",
      " [ 3  0  2 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  1]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  2  0  4]] \n",
      "\n",
      "Accuracy: 0.5334008097165992\n",
      "Precision: 0.2570110398454902\n",
      "Recall: 0.19713569655509228\n",
      "F1 score: 0.21079322763378083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(valid_target, y_predictition, average='macro')\n",
    "precision = precision_score(valid_target, y_predictition, average='macro')\n",
    "f1score = f1_score(valid_target, y_predictition, average='macro')\n",
    "accuracy = accuracy_score(valid_target, y_predictition)\n",
    "\n",
    "print('Confusion Matrix:\\n',confusion_matrix(valid_target, y_predictition),'\\n')\n",
    "print('Accuracy:', str(accuracy))\n",
    "print('Precision:', str(precision))\n",
    "print('Recall:', str(recall))\n",
    "print('F1 score:', str(f1score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prediction on a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = grid_svm.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>q-fin.EC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>math.CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cond-mat.quant-gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7405</th>\n",
       "      <td>7406</td>\n",
       "      <td>q-bio.PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7406</th>\n",
       "      <td>7407</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7407</th>\n",
       "      <td>7408</td>\n",
       "      <td>q-bio.QM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7408</th>\n",
       "      <td>7409</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7409</th>\n",
       "      <td>7410</td>\n",
       "      <td>physics.ins-det</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7410 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_id               Label\n",
       "0           1            q-fin.EC\n",
       "1           2                  cs\n",
       "2           3                  cs\n",
       "3           4             math.CT\n",
       "4           5  cond-mat.quant-gas\n",
       "...       ...                 ...\n",
       "7405     7406            q-bio.PE\n",
       "7406     7407                  cs\n",
       "7407     7408            q-bio.QM\n",
       "7408     7409                  cs\n",
       "7409     7410     physics.ins-det\n",
       "\n",
       "[7410 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"Label\"] = test_target\n",
    "test_df['test_id'] = list(range(1,len(test_df)+1))\n",
    "\n",
    "del test_df['Words']\n",
    "final = test_df[['test_id', 'Label']]\n",
    "\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('./Predictions_SVM.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
